{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Chat Generated Articles from OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Set api key here, left empty for account privacy reasons. You can add you own api key if you want to try\n",
    "openai.api_key = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"C:\\\\Users\\\\graduate\\\\Box\\\\Courses taken\\\\CS 6830 Data Science in practice\\\\Final project\\\\openai_api.txt\", 'r') as f:\n",
    "#     api_key = f.read().strip()\n",
    "\n",
    "# # Set api key here, left empty for account privacy reasons. You can add you own api key if you want to try\n",
    "# openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# articles is a list of dictionaries. Each dictionary contains all the information needed to generate one news article.\n",
    "# Information is gotten by scraping existing articles online\n",
    "# Currently, the prompt requires the the new organization: 'source', wordcount the generated article should be: 'wordcount'\n",
    "# and the headline: 'headline'. An example is shown below\n",
    "articles = [{'source':'CNN', 'wordcount':'200', 'headline':'What is the Good Friday Agreement? How a historic deal ended the Troubles in Northern Ireland'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFakeArticles(articles):\n",
    "    fakeArticles = pd.DataFrame(columns=['Headline', 'Content'])\n",
    "    for article in articles:\n",
    "        prompt=[\n",
    "            {\"role\": \"system\", \"content\": f\"You are a journalist at {article['source']}\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Write an article with about {article['wordcount']} words with the headline '{article['headline']}'\"},\n",
    "        ]\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=prompt\n",
    "        )\n",
    "        fakeArticles.loc[len(fakeArticles.index)] = [article['headline'], response['choices'][0]['message']['content']]\n",
    "        print(f'Articles created: {len(fakeArticles)}')\n",
    "\n",
    "        time.sleep(5)\n",
    "\n",
    "    return fakeArticles"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make CNN Fake Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('CNN500_items.csv')\n",
    "\n",
    "# ai_50 = df.sample(frac = 0.5)\n",
    "# real_50 = df.drop(ai_50.index)\n",
    "\n",
    "# articles = []\n",
    "# for index, row in ai_50.iterrows():\n",
    "#     articles.append({'source':'CNN','wordcount':len(row.Description.replace('\\n','').split(' ')),'headline':row.Title.replace('\\n','').strip()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ai_gen = getFakeArticles(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ai_gen.columns = ['Title', 'Content']\n",
    "# ai_gen['Source'] = 1\n",
    "\n",
    "# non_ai = real_50[['Title', 'Description']]\n",
    "# non_ai.columns = ['Title', 'Content']\n",
    "# non_ai['Source'] = 0\n",
    "\n",
    "# cnn_mixed = pd.concat([ai_gen, non_ai], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn_mixed.to_csv(path_or_buf=\"cnn_mixed.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make AP Fake Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('AP501dataset.csv')\n",
    "\n",
    "# df.loc[0].text\n",
    "# ai_50 = df.sample(frac = 0.5)\n",
    "# real_50 = df.drop(ai_50.index)\n",
    "\n",
    "# articles = []\n",
    "# for index, row in ai_50.iterrows():\n",
    "#     articles.append({'source':'AP News','wordcount':len(row.text.replace('\\n','').split(' ')),'headline':row.title.replace('\\n','').strip()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ai_gen = getFakeArticles(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ai_gen.columns = ['Title', 'Content']\n",
    "# ai_gen['Source'] = 1\n",
    "\n",
    "# non_ai = real_50[['title', 'text']]\n",
    "# non_ai.columns = ['Title', 'Content']\n",
    "# non_ai['Source'] = 0\n",
    "\n",
    "# ap_mixed = pd.concat([ai_gen, non_ai], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ap_mixed.to_csv(\"ap_mixed.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Fake Fox News Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('fox260.csv')\n",
    "\n",
    "# ai_50 = df.sample(frac = 0.5)\n",
    "# real_50 = df.drop(ai_50.index)\n",
    "\n",
    "# articles = []\n",
    "# for index, row in ai_50.iterrows():\n",
    "#     articles.append({'source':'Fox News','wordcount':len(row.text.replace('\\n','').split(' ')),'headline':row.title.replace('\\n','').strip()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ai_gen = getFakeArticles(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ai_gen.columns = ['Title', 'Content']\n",
    "# ai_gen['Source'] = 1\n",
    "\n",
    "# non_ai = real_50[['title', 'text']]\n",
    "# non_ai.columns = ['Title', 'Content']\n",
    "# non_ai['Source'] = 0\n",
    "\n",
    "# fox_mixed = pd.concat([ai_gen, non_ai], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fox_mixed.to_csv(\"fox_mixed.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Megh's Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the three CSV files into separate DataFrames\n",
    "ap_mixed1 = pd.read_csv('ap_mixed.csv')\n",
    "display(ap_mixed1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_mixed1 = pd.read_csv('cnn_mixed.csv')\n",
    "display(cnn_mixed1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fox_mixed1 = pd.read_csv('fox_mixed.csv')\n",
    "display(fox_mixed1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### merging 3 datasets into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the three DataFrames vertically (row-wise)\n",
    "dataset = pd.concat([ap_mixed1, cnn_mixed1, fox_mixed1], ignore_index=True).reset_index()\n",
    "dataset[750:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Optionally, you can drop duplicates if needed\n",
    "# dataset.drop_duplicates(inplace=True)\n",
    "\n",
    "dataset['Content'].replace('', np.nan, inplace=True)\n",
    "\n",
    "#drop NA values\n",
    "dataset = dataset.dropna()\n",
    "\n",
    "# Select only specific columns from the dataset\n",
    "selected_columns = ['Title', 'Content', 'Source']\n",
    "dataset_final = dataset[selected_columns]\n",
    "\n",
    "display(dataset_final)\n",
    "#final_dataset = dataset_final.to_csv('final_dataset.csv')\n",
    "dataset_final.shape\n",
    "# dataset_final.info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "countplot of the real and fake news articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=dataset,x='Source')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert the Content column in all lower case words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Convert 'Content' column to lowercase\n",
    "dataset_final['L_Content'] = dataset_final['Content'].str.lower()\n",
    "dataset_final.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove stpwords and punctuation from the content of our news combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "stop = set(stopwords.words('english'))\n",
    "punctuations=string.punctuation\n",
    "dataset_final['L_Content'] = dataset_final.L_Content.apply(lambda x: ' '.join([word for word in x.split() \n",
    "                    if word not in (stop) and word[0] != '@' \n",
    "                    and word not in punctuations ]))\n",
    "dataset_final.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_final['L_Content'] = dataset_final['L_Content'].str.replace('[{}]'.format(string.punctuation), '')\n",
    "dataset_final.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tokenize the news content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the NLTK tokenizer\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing and Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "# Create an instance of the PorterStemmer class\n",
    "porter_stemmer = PorterStemmer()\n",
    "# Replace null values with an empty string\n",
    "dataset_final['L_Content'].fillna('', inplace=True)\n",
    "# Tokenize the 'Content' column only for non-null values\n",
    "dataset_final['L_Content'] = dataset_final['L_Content'].apply(lambda x: word_tokenize(x) if isinstance(x, str) else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for stemming\n",
    "def stem_words(tokens):\n",
    "    return [porter_stemmer.stem(token) for token in tokens]\n",
    "\n",
    "# Apply stemming to the 'Content' column\n",
    "dataset_final['L_Content'] = dataset_final['L_Content'].apply(stem_words)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a matrix with every unique word in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the list of words into a single string\n",
    "dataset_final['L_Content'] = dataset_final['L_Content'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)\n",
    "# Convert the 'Content' column to lowercase\n",
    "dataset_final['L_Content'] = dataset_final['L_Content'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(1,1), min_df=10)\n",
    "vectorized_tweets = cv.fit_transform(dataset_final['L_Content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into test and training dataset\n",
    "X=vectorized_tweets\n",
    "y=dataset_final['Source'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naïve Bayes classification produces good results when we use it for textual data analysis such as Natural Language Processing\n",
    "Gaussian NB: When we have continuous attribute values, we made an assumption that the values associated with each class are distributed according to Gaussian or Normal distribution\n",
    "Multinominal NB: Multinomial Naïve Bayes algorithm is preferred to use on data that is multinomially distributed. It is one of the standard algorithms which is used in text categorization classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit data to a multinomial Naive Bayes model\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "#display(y_pred)\n",
    "p,r,f,s = precision_recall_fscore_support(y_test, y_pred)\n",
    "print(p, r, f, s)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy claculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred_train = clf.predict(X_train)\n",
    "print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))\n",
    "print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for overfitting and underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the scores on training and test set\n",
    "print('Training set score: {:.4f}'.format(clf.score(X_train, y_train)))\n",
    "print('Test set score: {:.4f}'.format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "array = [[tp, fp],[fn, tn]]\n",
    "sns.heatmap(array, annot=True, annot_kws={\"size\": 16}, fmt='d', cmap='YlGnBu', vmin=0, vmax=140, cbar=True, linewidths=0.5, linecolor='k', square=True)\n",
    "sns.despine(left=False, right=False, top=False, bottom=False)\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "# plt.savefig('1x1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification accuracy\n",
    "classification_accuracy = (tp + tn) / float(tp + tn + fp + fn)\n",
    "print('Classification accuracy : {0:0.4f}'.format(classification_accuracy))\n",
    "\n",
    "#Classification error\n",
    "classification_error = (fp + fn) / float(tp + tn + fp + fn)\n",
    "print('Classification error : {0:0.4f}'.format(classification_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_article_sorted = clf.feature_log_prob_[0, :].argsort()[::-1]\n",
    "orig_article_sorted = clf.feature_log_prob_[1, :].argsort()[::-1]\n",
    "print('Orig article words:\\n', np.take(cv.get_feature_names_out(), orig_article_sorted[:50]))\n",
    "print('\\nFake article words:\\n', np.take(cv.get_feature_names_out(), orig_article_sorted[:50]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC-AUC\n",
    "ROC Curve\n",
    "Another tool to measure the classification model performance visually is ROC Curve. ROC Curve stands for Receiver Operating Characteristic Curve. An ROC Curve is a plot which shows the performance of a classification model at various classification threshold levels. The ROC Curve plots the True Positive Rate (TPR) against the False Positive Rate (FPR) at various threshold levels. In the ROC Curve, we will focus on the TPR (True Positive Rate) and FPR (False Positive Rate) of a single point. This will give us the general performance of the ROC curve which consists of the TPR and FPR at various threshold levels. So, an ROC Curve plots TPR vs FPR at different classification threshold levels. If we lower the threshold levels, it may result in more items being classified as positve. It will increase both True Positives (TP) and False Positives (FP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ROC Curve\n",
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test,y_pred,pos_label=1)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(fpr, tpr, linewidth=2)\n",
    "plt.plot([0,1], [0,1], 'k--' )\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.title('ROC curve for Multinominal NB for Predicting Fake News')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC AUC\n",
    "ROC AUC stands for Receiver Operating Characteristic - Area Under Curve. It is a technique to compare classifier performance. In this technique, we measure the area under the curve (AUC). A perfect classifier will have a ROC AUC equal to 1, whereas a purely random classifier will have a ROC AUC equal to 0.5.\n",
    "\n",
    "So, ROC AUC is the percentage of the ROC plot that is underneath the curve. ROC AUC is a single number summary of classifier performance. The higher the value, the better the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute ROC AUC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "ROC_AUC = roc_auc_score(y_test, y_pred)\n",
    "print('ROC AUC : {:.4f}'.format(ROC_AUC))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying 10-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(clf, X_train, y_train, cv = 10, scoring='accuracy')\n",
    "print('Cross-validation scores:{}'.format(scores))\n",
    "\n",
    "# compute Average cross-validation score\n",
    "print('Average cross-validation score: {:.4f}'.format(scores.mean()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Chat Generated Articles from OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Set api key here, left empty for account privacy reasons. You can add you own api key if you want to try\n",
    "openai.api_key = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"C:\\\\Users\\\\graduate\\\\Box\\\\Courses taken\\\\CS 6830 Data Science in practice\\\\Final project\\\\openai_api.txt\", 'r') as f:\n",
    "#     api_key = f.read().strip()\n",
    "\n",
    "# # Set api key here, left empty for account privacy reasons. You can add you own api key if you want to try\n",
    "# openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# articles is a list of dictionaries. Each dictionary contains all the information needed to generate one news article.\n",
    "# Information is gotten by scraping existing articles online\n",
    "# Currently, the prompt requires the the new organization: 'source', wordcount the generated article should be: 'wordcount'\n",
    "# and the headline: 'headline'. An example is shown below\n",
    "articles = [{'source':'CNN', 'wordcount':'200', 'headline':'What is the Good Friday Agreement? How a historic deal ended the Troubles in Northern Ireland'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFakeArticles(articles):\n",
    "    fakeArticles = pd.DataFrame(columns=['Headline', 'Content'])\n",
    "    for article in articles:\n",
    "        prompt=[\n",
    "            {\"role\": \"system\", \"content\": f\"You are a journalist at {article['source']}\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Write an article with about {article['wordcount']} words with the headline '{article['headline']}'\"},\n",
    "        ]\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=prompt\n",
    "        )\n",
    "        fakeArticles.loc[len(fakeArticles.index)] = [article['headline'], response['choices'][0]['message']['content']]\n",
    "        print(f'Articles created: {len(fakeArticles)}')\n",
    "\n",
    "        time.sleep(5)\n",
    "\n",
    "    return fakeArticles"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make CNN Fake Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('CNN500_items.csv')\n",
    "\n",
    "# ai_50 = df.sample(frac = 0.5)\n",
    "# real_50 = df.drop(ai_50.index)\n",
    "\n",
    "# articles = []\n",
    "# for index, row in ai_50.iterrows():\n",
    "#     articles.append({'source':'CNN','wordcount':len(row.Description.replace('\\n','').split(' ')),'headline':row.Title.replace('\\n','').strip()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ai_gen = getFakeArticles(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ai_gen.columns = ['Title', 'Content']\n",
    "# ai_gen['Source'] = 1\n",
    "\n",
    "# non_ai = real_50[['Title', 'Description']]\n",
    "# non_ai.columns = ['Title', 'Content']\n",
    "# non_ai['Source'] = 0\n",
    "\n",
    "# cnn_mixed = pd.concat([ai_gen, non_ai], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn_mixed.to_csv(path_or_buf=\"cnn_mixed.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make AP Fake Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('AP501dataset.csv')\n",
    "\n",
    "# df.loc[0].text\n",
    "# ai_50 = df.sample(frac = 0.5)\n",
    "# real_50 = df.drop(ai_50.index)\n",
    "\n",
    "# articles = []\n",
    "# for index, row in ai_50.iterrows():\n",
    "#     articles.append({'source':'AP News','wordcount':len(row.text.replace('\\n','').split(' ')),'headline':row.title.replace('\\n','').strip()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ai_gen = getFakeArticles(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ai_gen.columns = ['Title', 'Content']\n",
    "# ai_gen['Source'] = 1\n",
    "\n",
    "# non_ai = real_50[['title', 'text']]\n",
    "# non_ai.columns = ['Title', 'Content']\n",
    "# non_ai['Source'] = 0\n",
    "\n",
    "# ap_mixed = pd.concat([ai_gen, non_ai], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ap_mixed.to_csv(\"ap_mixed.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Fake Fox News Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('fox260.csv')\n",
    "\n",
    "# ai_50 = df.sample(frac = 0.5)\n",
    "# real_50 = df.drop(ai_50.index)\n",
    "\n",
    "# articles = []\n",
    "# for index, row in ai_50.iterrows():\n",
    "#     articles.append({'source':'Fox News','wordcount':len(row.text.replace('\\n','').split(' ')),'headline':row.title.replace('\\n','').strip()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ai_gen = getFakeArticles(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ai_gen.columns = ['Title', 'Content']\n",
    "# ai_gen['Source'] = 1\n",
    "\n",
    "# non_ai = real_50[['title', 'text']]\n",
    "# non_ai.columns = ['Title', 'Content']\n",
    "# non_ai['Source'] = 0\n",
    "\n",
    "# fox_mixed = pd.concat([ai_gen, non_ai], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fox_mixed.to_csv(\"fox_mixed.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

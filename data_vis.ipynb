{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction and Data Visualization\n",
    "\n",
    "ChatGPT's response when asked for traits that could be useful in identifying ai-generated articles.\n",
    "\n",
    "1)  Average sentence length: AI-generated articles may have longer or shorter sentences than human-written articles on average.\n",
    "\n",
    "2)  Punctuation usage: AI-generated articles may use certain types of punctuation, such as exclamation points or ellipses, more or less frequently than human-written articles.\n",
    "\n",
    "3)  Word frequency: AI-generated articles may use certain words more or less frequently than human-written articles. For example, AI-generated articles may use more technical or jargon-y terms, or may use certain phrases or idioms less frequently.\n",
    "\n",
    "4)  Part of speech tagging: By analyzing the parts of speech used in the article (such as nouns, verbs, and adjectives), we may be able to identify patterns that are more common in AI-generated articles.\n",
    "\n",
    "5)  Named entity recognition: By analyzing the named entities (such as people, places, and organizations) mentioned in the article, we may be able to identify patterns that are more common in AI-generated articles.\n",
    "\n",
    "6)  Syntactic complexity: By analyzing the complexity of sentence structures (such as the number of dependent clauses or subordinating conjunctions used), we may be able to identify patterns that are more common in AI-generated articles.\n",
    "\n",
    "7)  Readability score: By calculating a readability score (such as the Flesch-Kincaid readability score), we may be able to identify patterns that are more common in AI-generated articles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import string\n",
    "import scipy.stats as stats\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from readability import Readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"final_dataset.csv\")\n",
    "df['Content'].replace('', np.nan, inplace=True)\n",
    "df['Content'] = df.Content.apply(lambda x : x.strip()) #to remove the whitespace from the beginning and at the end of the string\n",
    "df['Title'] = df.Title.apply(lambda x : x.strip())\n",
    "\n",
    "\n",
    "#drop NA values\n",
    "df = df.dropna()\n",
    "\n",
    "# Select only specific columns from the dataset\n",
    "selected_columns = ['Title', 'Content', 'Source']\n",
    "df = df[selected_columns]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Sentence Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_sentence_length(text):\n",
    "    # Split text into sentences using regular expressions\n",
    "    sentences = re.findall(r'\\b[\\w\\s\\',-]+\\b[.?!]', text)\n",
    "    # Calculate the average sentence length\n",
    "    total_words = sum(len(sentence.split()) for sentence in sentences)\n",
    "    num_sentences = len(sentences)\n",
    "    if num_sentences > 0:\n",
    "        return total_words / num_sentences\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AvgSentenceLength'] = df.Content.apply(lambda x : average_sentence_length(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai = df[df.Source == 1]\n",
    "real = df[df.Source == 0]\n",
    "real = real.dropna()\n",
    "\n",
    "\n",
    "print(f'Mean sentence length for ai articles: {ai.AvgSentenceLength.mean()}, std: {ai.AvgSentenceLength.std()}')\n",
    "print(f'Mean sentence length for real articles: {real.AvgSentenceLength.mean()}, std: {real.AvgSentenceLength.std()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 2, figsize=(9,4))\n",
    "axes[0].set_xlim(5, 40)\n",
    "axes[1].set_xlim(5, 40)\n",
    "sns.histplot(ai, x='AvgSentenceLength', color=\"orchid\", ax=axes[0]).set(title='Average Sentence Length of AI articles')\n",
    "sns.histplot(real, x='AvgSentenceLength', color=\"skyblue\", ax=axes[1]).set(title='Average Sentence Length of Real articles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = real.dropna()\n",
    "stats.ttest_ind(ai.AvgSentenceLength, real.AvgSentenceLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "stats.pointbiserialr(df.AvgSentenceLength, df.Source)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Punctuation Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_punctuation_percentage(text):\n",
    "    # Remove all whitespace characters from the text\n",
    "    text = \"\".join(text.split())\n",
    "\n",
    "    # Calculate the length of the text and the length of the punctuation characters\n",
    "    text_length = len(text)\n",
    "    punctuation_length = len([c for c in text if c in string.punctuation])\n",
    "\n",
    "    # Calculate the percentage of the text that is punctuation\n",
    "    punctuation_percentage = (punctuation_length / text_length) * 100\n",
    "\n",
    "    return punctuation_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PunctuationPercentage'] = df.Content.apply(lambda x : calculate_punctuation_percentage(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai = df[df.Source == 1]\n",
    "real = df[df.Source == 0]\n",
    "\n",
    "\n",
    "print(f'Mean punctuation percentage for ai articles: {ai.PunctuationPercentage.mean()}, std: {ai.PunctuationPercentage.std()}')\n",
    "print(f'Mean punctuation percentage for real articles: {real.PunctuationPercentage.mean()}, std: {real.PunctuationPercentage.std()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 2, figsize=(9,4))\n",
    "axes[0].set_xlim(0, 9)\n",
    "axes[1].set_xlim(0, 9)\n",
    "sns.histplot(ai, x='PunctuationPercentage', color=\"orchid\", ax=axes[0]).set(title='Punctuation Percentage of AI articles')\n",
    "sns.histplot(real, x='PunctuationPercentage', color=\"skyblue\", ax=axes[1]).set(title='Punctuation Percentage of Real articles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = real.dropna()\n",
    "stats.ttest_ind(ai.PunctuationPercentage, real.PunctuationPercentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "stats.pointbiserialr(df.PunctuationPercentage, df.Source)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More specific punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_period_percentage(text):\n",
    "    # Remove all whitespace characters from the text\n",
    "    text = \"\".join(text.split())\n",
    "\n",
    "    # Calculate the length of the text and the length of the punctuation characters\n",
    "    period_length = len([c for c in text if c == '.'])\n",
    "    punctuation_length = len([c for c in text if c in string.punctuation])\n",
    "\n",
    "    # Calculate the percentage of the text that is punctuation\n",
    "    period_percentage = (period_length / punctuation_length) * 100\n",
    "\n",
    "    return period_percentage\n",
    "\n",
    "def calculate_comma_percentage(text):\n",
    "    # Remove all whitespace characters from the text\n",
    "    text = \"\".join(text.split())\n",
    "\n",
    "    # Calculate the length of the text and the length of the punctuation characters\n",
    "    comma_length = len([c for c in text if c == ','])\n",
    "    punctuation_length = len([c for c in text if c in string.punctuation])\n",
    "\n",
    "    # Calculate the percentage of the text that is punctuation\n",
    "    comma_percentage = (comma_length / punctuation_length) * 100\n",
    "\n",
    "    return comma_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PeriodPercentage'] = df.Content.apply(lambda x : calculate_period_percentage(x))\n",
    "df['CommaPercentage'] = df.Content.apply(lambda x : calculate_comma_percentage(x))\n",
    "df['OtherPercentage'] = df.Content.apply(lambda x : 100 - calculate_comma_percentage(x) - calculate_period_percentage(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai = df[df.Source == 1]\n",
    "real = df[df.Source == 0]\n",
    "\n",
    "\n",
    "print(f'Mean period percentage for ai articles: {ai.PeriodPercentage.mean()}, std: {ai.PeriodPercentage.std()}')\n",
    "print(f'Mean period percentage for real articles: {real.PeriodPercentage.mean()}, std: {real.PeriodPercentage.std()}\\n')\n",
    "print(f'Mean comma percentage for ai articles: {ai.CommaPercentage.mean()}, std: {ai.CommaPercentage.std()}')\n",
    "print(f'Mean comma percentage for real articles: {real.CommaPercentage.mean()}, std: {real.CommaPercentage.std()}\\n')\n",
    "print(f'Mean other percentage for ai articles: {ai.OtherPercentage.mean()}, std: {ai.OtherPercentage.std()}')\n",
    "print(f'Mean other percentage for real articles: {real.OtherPercentage.mean()}, std: {real.OtherPercentage.std()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 2, figsize=(9,4))\n",
    "axes[0].set_xlim(10, 80)\n",
    "axes[1].set_xlim(10, 80)\n",
    "sns.histplot(ai, x='PeriodPercentage', color=\"orchid\", ax=axes[0]).set(title='Period Percentage of AI articles')\n",
    "sns.histplot(real, x='PeriodPercentage', color=\"skyblue\", ax=axes[1]).set(title='Period Percentage of Real articles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 2, figsize=(9,4))\n",
    "axes[0].set_xlim(0, 70)\n",
    "axes[1].set_xlim(0, 70)\n",
    "sns.histplot(ai, x='CommaPercentage', color=\"orchid\", ax=axes[0]).set(title='Comma Percentage of AI articles')\n",
    "sns.histplot(real, x='CommaPercentage', color=\"skyblue\", ax=axes[1]).set(title='Comma Percentage of Real articles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 2, figsize=(9,4))\n",
    "axes[0].set_xlim(0, 70)\n",
    "axes[1].set_xlim(0, 70)\n",
    "sns.histplot(ai, x='OtherPercentage', color=\"orchid\", ax=axes[0]).set(title='Other Percentage of AI articles')\n",
    "sns.histplot(real, x='OtherPercentage', color=\"skyblue\", ax=axes[1]).set(title='Other Percentage of Real articles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = real.dropna()\n",
    "print(stats.ttest_ind(ai.PeriodPercentage, real.PeriodPercentage))\n",
    "real = real.dropna()\n",
    "print(stats.ttest_ind(ai.CommaPercentage, real.CommaPercentage))\n",
    "real = real.dropna()\n",
    "print(stats.ttest_ind(ai.OtherPercentage, real.OtherPercentage))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary Frequency\n",
    "\n",
    "Uses a type-token ration, basically the number of unique words / total number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocabulary_richness(text):\n",
    "    # Tokenize the text into words\n",
    "    words = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Calculate the number of unique words (types)\n",
    "    types = set(words)\n",
    "    num_types = len(types)\n",
    "    \n",
    "    # Calculate the total number of words (tokens)\n",
    "    num_tokens = len(words)\n",
    "    \n",
    "    # Calculate the type-token ratio\n",
    "    if num_tokens > 0:\n",
    "        ttr = num_types / num_tokens*100\n",
    "    else:\n",
    "        ttr = 0\n",
    "        \n",
    "    return ttr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['VocabRichness'] = df.Content.apply(lambda x : vocabulary_richness(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai = df[df.Source == 1]\n",
    "real = df[df.Source == 0]\n",
    "\n",
    "\n",
    "print(f'Mean Vocab richness percentage for ai articles: {ai.VocabRichness.mean()}, std: {ai.VocabRichness.std()}')\n",
    "print(f'Mean Vocab richness percentage for real articles: {real.VocabRichness.mean()}, std: {real.VocabRichness.std()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 2, figsize=(9,4))\n",
    "axes[0].set_xlim(0, 9)\n",
    "axes[1].set_xlim(0, 9)\n",
    "sns.histplot(ai, x='VocabRichness', color=\"orchid\", ax=axes[0]).set(title='Vocabulary Richness of AI articles')\n",
    "sns.histplot(real, x='VocabRichness', color=\"skyblue\", ax=axes[1]).set(title='Vocabulary Richness of Real articles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = real.dropna()\n",
    "stats.ttest_ind(ai.VocabRichness, real.VocabRichness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "stats.pointbiserialr(df.VocabRichness, df.Source)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parts of Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parts_of_speech(text):\n",
    "    # Tokenize the text into words\n",
    "    words = nltk.word_tokenize(text)\n",
    "\n",
    "    # Tag each word with its part of speech\n",
    "    tagged_words = nltk.pos_tag(words)\n",
    "\n",
    "    # Count the number of each part of speech\n",
    "    counts = Counter(tag for word, tag in tagged_words)\n",
    "    counts = dict(counts)\n",
    "\n",
    "    noun = 0\n",
    "    verb = 0\n",
    "    adverb = 0\n",
    "    pronoun = 0\n",
    "    adjective = 0\n",
    "    for i in counts:\n",
    "        if i.startswith('NN'):\n",
    "            noun += counts[i]\n",
    "        elif i.startswith('VB'):\n",
    "            verb += counts[i]\n",
    "        elif i.startswith('RB'):\n",
    "            adverb += counts[i]\n",
    "        elif i.startswith('PRP'):\n",
    "            pronoun += counts[i]\n",
    "        elif i.startswith('JJ'):\n",
    "            adjective += counts[i]\n",
    "\n",
    "    wc = len(text.split(' '))\n",
    "\n",
    "    return {'noun':noun/wc, 'verb':verb/wc, 'adverb':adverb/wc, 'pronoun':pronoun/wc, 'adjective':adjective/wc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pos'] = df.Content.apply(lambda x : count_parts_of_speech(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Noun'] = df.pos.apply(lambda x : x['noun'])\n",
    "df['Verb'] = df.pos.apply(lambda x : x['verb'])\n",
    "df['Adverb'] = df.pos.apply(lambda x : x['adverb'])\n",
    "df['Pronoun'] = df.pos.apply(lambda x : x['pronoun'])\n",
    "df['Adjective'] = df.pos.apply(lambda x : x['adjective'])\n",
    "df = df.drop(labels=['pos'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai = df[df.Source == 1]\n",
    "real = df[df.Source == 0]\n",
    "\n",
    "print(f'Mean Noun percentage for ai articles: {ai.Noun.mean()}, std: {ai.Noun.std()}')\n",
    "print(f'Mean Noun percentage for real articles: {real.Noun.mean()}, std: {real.Noun.std()}\\n')\n",
    "print(f'Mean Verb percentage for ai articles: {ai.Verb.mean()}, std: {ai.Verb.std()}')\n",
    "print(f'Mean Verb percentage for real articles: {real.Verb.mean()}, std: {real.Verb.std()}\\n')\n",
    "print(f'Mean Adverb percentage for ai articles: {ai.Adverb.mean()}, std: {ai.Adverb.std()}')\n",
    "print(f'Mean Adverb percentage for real articles: {real.Adverb.mean()}, std: {real.Adverb.std()}\\n')\n",
    "print(f'Mean Pronoun percentage for ai articles: {ai.Pronoun.mean()}, std: {ai.Pronoun.std()}')\n",
    "print(f'Mean Pronoun percentage for real articles: {real.Pronoun.mean()}, std: {real.Pronoun.std()}\\n')\n",
    "print(f'Mean Adjective percentage for ai articles: {ai.Adjective.mean()}, std: {ai.Adjective.std()}')\n",
    "print(f'Mean Adjective percentage for real articles: {real.Adjective.mean()}, std: {real.Adjective.std()}\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named entity recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_named_entities(text):\n",
    "    # Tokenize the input text into sentences\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "    # Tokenize each sentence into words and tag the words with part-of-speech labels\n",
    "    tokenized_sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "    tagged_sentences = [nltk.pos_tag(sent) for sent in tokenized_sentences]\n",
    "\n",
    "    # Use NLTK's named entity recognizer to identify named entities in the tagged sentences\n",
    "    chunked_sentences = nltk.ne_chunk_sents(tagged_sentences, binary=True)\n",
    "\n",
    "    # Extract the named entities and their labels from the chunked sentences\n",
    "    named_entities = []\n",
    "    for chunked_sent in chunked_sentences:\n",
    "        for tree in chunked_sent:\n",
    "            if hasattr(tree, 'label') and tree.label() == 'NE':\n",
    "                named_entities.append(' '.join([child[0] for child in tree]))\n",
    "\n",
    "    # Count the number of each named entity type\n",
    "    counts = Counter(named_entities)\n",
    "\n",
    "    count = 0\n",
    "    for item in counts.values():\n",
    "        count += item\n",
    "\n",
    "    return count / len(text.split(\" \")) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['NamedEntities'] = df.Content.apply(lambda x : count_named_entities(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai = df[df.Source == 1]\n",
    "real = df[df.Source == 0]\n",
    "\n",
    "print(f'Mean Named Entities Frequency for real articles: {real.NamedEntities.mean()}, std: {real.NamedEntities.std()}')\n",
    "print(f'Mean Named Entities Frequency for ai articles: {ai.NamedEntities.mean()}, std: {ai.NamedEntities.std()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 2, figsize=(9,4))\n",
    "axes[0].set_xlim(0, 20)\n",
    "axes[1].set_xlim(0, 20)\n",
    "sns.histplot(ai, x='NamedEntities', color=\"orchid\", ax=axes[0]).set(title='Named Entities Frequency of AI articles')\n",
    "sns.histplot(real, x='NamedEntities', color=\"skyblue\", ax=axes[1]).set(title='Named Entities Frequency of Real articles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(ai.NamedEntities, real.NamedEntities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.pointbiserialr(df.NamedEntities, df.Source)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntactic complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Readability score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_readability(text):\n",
    "    if len(text.split(' ')) > 100:\n",
    "        r = Readability(text)\n",
    "        return r.flesch_kincaid().score\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Readability'] = df.Content.apply(lambda x : compute_readability(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai = df[df.Source == 1]\n",
    "real = df[df.Source == 0]\n",
    "\n",
    "print(f'Mean Readability Score for ai articles: {ai.Readability.mean()}, std: {ai.Readability.std()}')\n",
    "print(f'Mean Readability Score for real articles: {real.Readability.mean()}, std: {real.Readability.std()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 2, figsize=(9,4))\n",
    "axes[0].set_xlim(0, 25)\n",
    "axes[1].set_xlim(0, 25)\n",
    "sns.histplot(ai, x='Readability', color=\"orchid\", ax=axes[0]).set(title='Readability Score of AI articles')\n",
    "sns.histplot(real, x='Readability', color=\"skyblue\", ax=axes[1]).set(title='Readability Score of Real articles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = real.dropna()\n",
    "ai = ai.dropna()\n",
    "stats.ttest_ind(ai.Readability, real.Readability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "stats.pointbiserialr(df.Readability, df.Source)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

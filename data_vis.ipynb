{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction and Data Visualization\n",
    "\n",
    "ChatGPT's response when asked for traits that could be useful in identifying ai-generated articles.\n",
    "\n",
    "1)  Average sentence length: AI-generated articles may have longer or shorter sentences than human-written articles on average.\n",
    "\n",
    "2)  Punctuation usage: AI-generated articles may use certain types of punctuation, such as exclamation points or ellipses, more or less frequently than human-written articles.\n",
    "\n",
    "3)  Word frequency: AI-generated articles may use certain words more or less frequently than human-written articles. For example, AI-generated articles may use more technical or jargon-y terms, or may use certain phrases or idioms less frequently.\n",
    "\n",
    "4)  Part of speech tagging: By analyzing the parts of speech used in the article (such as nouns, verbs, and adjectives), we may be able to identify patterns that are more common in AI-generated articles.\n",
    "\n",
    "5)  Named entity recognition: By analyzing the named entities (such as people, places, and organizations) mentioned in the article, we may be able to identify patterns that are more common in AI-generated articles.\n",
    "\n",
    "6)  Syntactic complexity: By analyzing the complexity of sentence structures (such as the number of dependent clauses or subordinating conjunctions used), we may be able to identify patterns that are more common in AI-generated articles.\n",
    "\n",
    "7)  Readability score: By calculating a readability score (such as the Flesch-Kincaid readability score), we may be able to identify patterns that are more common in AI-generated articles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import string\n",
    "import scipy.stats as stats\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"final_dataset.csv\")\n",
    "df['Content'].replace('', np.nan, inplace=True)\n",
    "df['Content'] = df.Content.apply(lambda x : x.strip())\n",
    "df['Title'] = df.Title.apply(lambda x : x.strip())\n",
    "\n",
    "\n",
    "#drop NA values\n",
    "df = df.dropna()\n",
    "\n",
    "# Select only specific columns from the dataset\n",
    "selected_columns = ['Title', 'Content', 'Source']\n",
    "df = df[selected_columns]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Sentence Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_sentence_length(text):\n",
    "    # Split text into sentences using regular expressions\n",
    "    sentences = re.findall(r'\\b[\\w\\s\\',-]+\\b[.?!]', text)\n",
    "    # Calculate the average sentence length\n",
    "    total_words = sum(len(sentence.split()) for sentence in sentences)\n",
    "    num_sentences = len(sentences)\n",
    "    if num_sentences > 0:\n",
    "        return total_words / num_sentences\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AvgSentenceLength'] = df.Content.apply(lambda x : average_sentence_length(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai = df[df.Source == 1]\n",
    "real = df[df.Source == 0]\n",
    "real = real.dropna()\n",
    "\n",
    "\n",
    "print(f'Mean sentence length for ai articles: {ai.AvgSentenceLength.mean()}, std: {ai.AvgSentenceLength.std()}')\n",
    "print(f'Mean sentence length for real articles: {real.AvgSentenceLength.mean()}, std: {real.AvgSentenceLength.std()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 2, figsize=(9,4))\n",
    "axes[0].set_xlim(5, 45)\n",
    "axes[1].set_xlim(5, 45)\n",
    "sns.histplot(ai, x='AvgSentenceLength', color=\"orchid\", ax=axes[0]).set(title='Average Sentence Length of AI articles')\n",
    "sns.histplot(real, x='AvgSentenceLength', color=\"skyblue\", ax=axes[1]).set(title='Average Sentence Length of Real articles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = real.dropna()\n",
    "stats.ttest_ind(ai.AvgSentenceLength, real.AvgSentenceLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "stats.pearsonr(df.AvgSentenceLength, df.Source)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Punctuation Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_punctuation_percentage(text):\n",
    "    # Remove all whitespace characters from the text\n",
    "    text = \"\".join(text.split())\n",
    "\n",
    "    # Calculate the length of the text and the length of the punctuation characters\n",
    "    text_length = len(text)\n",
    "    punctuation_length = len([c for c in text if c in string.punctuation])\n",
    "\n",
    "    # Calculate the percentage of the text that is punctuation\n",
    "    punctuation_percentage = (punctuation_length / text_length) * 100\n",
    "\n",
    "    return punctuation_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PunctuationPercentage'] = df.Content.apply(lambda x : calculate_punctuation_percentage(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai = df[df.Source == 1]\n",
    "real = df[df.Source == 0]\n",
    "\n",
    "\n",
    "print(f'Mean punctuation percentage for ai articles: {ai.PunctuationPercentage.mean()}, std: {ai.PunctuationPercentage.std()}')\n",
    "print(f'Mean punctuation percentage for real articles: {real.PunctuationPercentage.mean()}, std: {real.PunctuationPercentage.std()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 2, figsize=(9,4))\n",
    "axes[0].set_xlim(0, 9)\n",
    "axes[1].set_xlim(0, 9)\n",
    "sns.histplot(ai, x='PunctuationPercentage', color=\"orchid\", ax=axes[0]).set(title='Punctuation Percentage of AI articles')\n",
    "sns.histplot(real, x='PunctuationPercentage', color=\"skyblue\", ax=axes[1]).set(title='Punctuation Percentage of Real articles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = real.dropna()\n",
    "stats.ttest_ind(ai.PunctuationPercentage, real.PunctuationPercentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "stats.pearsonr(df.AvgSentenceLength, df.Source)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary Frequency\n",
    "\n",
    "Uses a type-token ration, basically the number of unique words / total number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocabulary_richness(text):\n",
    "    # Tokenize the text into words\n",
    "    words = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Calculate the number of unique words (types)\n",
    "    types = set(words)\n",
    "    num_types = len(types)\n",
    "    \n",
    "    # Calculate the total number of words (tokens)\n",
    "    num_tokens = len(words)\n",
    "    \n",
    "    # Calculate the type-token ratio\n",
    "    if num_tokens > 0:\n",
    "        ttr = num_types / num_tokens\n",
    "    else:\n",
    "        ttr = 0\n",
    "        \n",
    "    return ttr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['VocabRichness'] = df.Content.apply(lambda x : vocabulary_richness(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai = df[df.Source == 1]\n",
    "real = df[df.Source == 0]\n",
    "\n",
    "\n",
    "print(f'Mean punctuation percentage for ai articles: {ai.VocabRichness.mean()}, std: {ai.VocabRichness.std()}')\n",
    "print(f'Mean punctuation percentage for real articles: {real.VocabRichness.mean()}, std: {real.VocabRichness.std()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 2, figsize=(9,4))\n",
    "# axes[0].set_xlim(0, 9)\n",
    "# axes[1].set_xlim(0, 9)\n",
    "sns.histplot(ai, x='VocabRichness', color=\"orchid\", ax=axes[0]).set(title='Vocabulary Richness of AI articles')\n",
    "sns.histplot(real, x='VocabRichness', color=\"skyblue\", ax=axes[1]).set(title='Vocabulary Richness of Real articles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai.sort_values(by='VocabRichness').tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
